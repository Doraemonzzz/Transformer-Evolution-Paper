# 标题

论文地址：

- [https://arxiv.org/abs/2004.08249](https://arxiv.org/abs/2004.08249)

参考资料：

- [http://www.linzehui.me/2020/09/19/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8739/](http://www.linzehui.me/2020/09/19/%E8%AE%BA%E6%96%87/%E6%AF%8F%E5%91%A8%E8%AE%BA%E6%96%8739/)



## 整体思路以及计算方式

首先回顾PreNorm和PostNorm：

- PreNorm：$\mathbf y = \mathbf x+ f(\mathrm{Norm}(\mathbf x))$；
- PostNorm：$\mathbf y = \mathrm{Norm}(\mathbf x+ f(\mathbf x))$；

都知道PostNorm训练更不稳定，作者分析后得出原因是，PostNorm中$f(\mathbf x)$占的比例非常大，而PreNorm中$f(\mathbf x)$占的比例相对较小，作者提供的解决方案是，将PostNorm的公式修改为：
$$
\mathbf y = \mathrm{Norm}(w.\mathbf x+ f(\mathbf x)).
$$
其中$w$是估计得到的参数。



## 简评

根据这个思路，可以对PreNorm做一个改进：
$$
\mathbf y = \mathrm{Norm}(\mathbf x+ w.f(\mathbf x)).
$$
