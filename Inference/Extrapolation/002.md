# Structured Prompting: Scaling In-Context Learning to 1,000 Examples

论文地址：

- [https://arxiv.org/pdf/2212.06713.pdf](https://arxiv.org/pdf/2212.06713.pdf)



## 整体思路以及计算方式

提供了一个让LM处理更长序列的思路，图示如下：

![](../../.Photo/Inference/Extrapolation/002.jpg)

步骤：

- 将输入拆成$$M$$组，组内位置编码右对齐，统一为$$p_{n}, p_{n-1},\ldots$$，输入的位置编码为$$p_{n+1}$$；
- 组内做attention，得到$$M$$组向量$$\mathbf y_{\mathcal Z_i}$$，$$\mathcal Z_i =\{1+\sum_{j<i} N_j,\ldots,\sum_{j\le i}N_j  \}$$；
- 将输入$$\mathbf x$$作为query，$$\mathbf x, \mathbf y_{\mathcal Z_1}, \ldots, \mathbf y_{\mathcal Z_M}$$作为key, value做attention得到最终结果；
  - 注意$$\mathbf x$$和$$\mathbf x$$的attention score加强了$$M$$倍；



## 代码

- [https://github.com/microsoft/LMOps/tree/main/structured_prompting/fairseq-version](https://github.com/microsoft/LMOps/tree/main/structured_prompting/fairseq-version)



## 简评

还可以的思路，不过细节得看代码。